{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Value: -1.0\n",
      "Max Value: 0.999969482421875\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import sys\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# URL of the raw wave file on GitHub\n",
    "# un-comment the URL of the file you want to use\n",
    "# ATF Drums\n",
    "#github_url = \"https://raw.githubusercontent.com/kevbrnen/Music-Technology-Final-Project/main/Sound%20Examples/Testing_Files/Around%20the%20fur%20drums.wav\"\n",
    "# KYW inst\n",
    "github_url = \"https://raw.githubusercontent.com/kevbrnen/Music-Technology-Final-Project/main/Sound%20Examples/Testing_Files/KYW%20Inst.wav\"\n",
    "\n",
    "# Fetch the wave file from GitHub\n",
    "response = requests.get(github_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Read the wave data from the response content\n",
    "    wave_data = io.BytesIO(response.content)\n",
    "    \n",
    "    # Read the wave file \n",
    "    fs, data = wavfile.read(wave_data)\n",
    "    \n",
    "else:\n",
    "    print(\"Failed to fetch the wave file from GitHub\")\n",
    "\n",
    "\n",
    "# Get the bit depth of the audio data (assumes audio_data is a NumPy array)\n",
    "bit_depth = data.dtype.itemsize * 8\n",
    "\n",
    "# Calculate the scaling factor for normalization\n",
    "scaling_factor = 2 ** (bit_depth - 1)  # For signed audio\n",
    "\n",
    "# Convert audio data to floating-point values and normalize\n",
    "data = data.astype(np.float32) / scaling_factor\n",
    "\n",
    "# Verify that the data is now in the range -1 to 1\n",
    "print(f\"Min Value: {np.min(data)}\")\n",
    "print(f\"Max Value: {np.max(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Testing individual circular buffers ####\n",
    "\n",
    "delay_ms = 103.745923 #Delay time in ms\n",
    "wet_amt = 0.5 #Wet amount (0 -> 1)\n",
    "\n",
    "# Delay time in samples for creating buffer\n",
    "delaySamps = ((delay_ms/1000) * fs)\n",
    "\n",
    "# Creating Left and Right buffers\n",
    "audio_bufferL = CircularBuffer(delaySamps)\n",
    "audio_bufferR = CircularBuffer(delaySamps+94)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio output array\n",
    "audio_out = np.zeros((len(data) + max(audio_bufferL.buffer_len(), audio_bufferR.buffer_len()), 2))\n",
    "\n",
    "# Processing Loop\n",
    "for i in range(len(audio_out)):\n",
    "    # Take next wet sample from buffer\n",
    "    delayedL = audio_bufferL.get_sample_from_buffer()\n",
    "    delayedR = audio_bufferR.get_sample_from_buffer()\n",
    "    \n",
    "    # Push next dry sample to buffer (if there are dry samples left)\n",
    "    if(i < len(data)):\n",
    "        audio_bufferL.push_sample_to_buffer(data[i, 0])\n",
    "        audio_bufferR.push_sample_to_buffer(data[i, 1])\n",
    "\n",
    "    # Combine with dry signal and put in output array\n",
    "    audio_out[i, 0] = (wet_amt * delayedL) \n",
    "    audio_out[i, 1] = (wet_amt * delayedR) \n",
    "    # Include dry if there is dry left\n",
    "    if(i < len(data)):\n",
    "        audio_out[i, 0] += ((1 - wet_amt) * data[i, 0])\n",
    "        audio_out[i, 1] += ((1 - wet_amt) * data[i, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(audio_out, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Testing Stereo Delay ####\n",
    "\n",
    "delay_ms = 103.745923 #Delay time in ms\n",
    "wet_amt = 0.4 #Wet amount (0 -> 1)\n",
    "\n",
    "# Delay time in samples for creating buffer\n",
    "delaySamps = ((delay_ms/1000) * fs)\n",
    "\n",
    "# Stereo buffer setup with differing delay amounts for each side\n",
    "stereoBuffer = StereoDelay(delaySamps, delaySamps+100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio output array\n",
    "stereo_audio_out = np.zeros((len(data) + stereoBuffer.buffer_maxLen(), 2))\n",
    "\n",
    "# Processing Loop\n",
    "for i in range(len(stereo_audio_out)):\n",
    "    # Take next wet sample from buffer\n",
    "    delayed_s = stereoBuffer.get_samples_from_buffer()\n",
    "    \n",
    "    # Push next dry sample to buffer (if there are dry samples left)\n",
    "    if(i < len(data)):\n",
    "        stereoBuffer.push_samples_to_buffer(data[i])\n",
    "\n",
    "    # Combine with dry signal and put in output array\n",
    "    stereo_audio_out[i] = np.multiply(wet_amt,delayed_s)\n",
    "\n",
    "    # Include dry if there is dry left\n",
    "    if(i < len(data)):\n",
    "        stereo_audio_out[i] += np.multiply((1 - wet_amt), data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(stereo_audio_out, fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
